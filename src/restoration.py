"""
Audio Restoration Pipeline for MusicGen Outputs

This module implements a multi-stage restoration pipeline to enhance
the quality of audio generated by models like MusicGen.

Author: Alessandro Lo Curcio
Date: 2025
"""

import numpy as np
import librosa
import soundfile as sf
import noisereduce as nr
from pedalboard import Pedalboard, Compressor, HighpassFilter, LowpassFilter
from scipy import signal
from typing import Optional, Tuple
import warnings
warnings.filterwarnings('ignore')


class AudioRestorer:
    """
    Multi-stage audio restoration pipeline.
    
    Stages:
        1. Spectral noise reduction
        2. Bandwidth extension
        3. Dynamic range compression
        4. Spectral shaping
        5. Normalization and dithering
    
    Args:
        sample_rate (int): Target sample rate in Hz
        verbose (bool): Print progress information
    
    Example:
        >>> restorer = AudioRestorer(sample_rate=32000)
        >>> restorer.restore('input.wav', 'output.wav')
    """
    
    def __init__(self, sample_rate: int = 32000, verbose: bool = True):
        self.sr = sample_rate
        self.verbose = verbose
        self._setup_pipeline()
    
    def _setup_pipeline(self):
        """Initialize audio processing components"""
        # Compression settings
        self.compressor = Pedalboard([
            Compressor(
                threshold_db=-20,
                ratio=4,
                attack_ms=10,
                release_ms=100
            )
        ])
        
        # EQ filters
        self.eq_filters = Pedalboard([
            HighpassFilter(cutoff_frequency_hz=20),
            LowpassFilter(cutoff_frequency_hz=20000)
        ])
    
    def denoise(self, audio: np.ndarray, 
                method: str = 'spectral',
                noise_reduction: float = 0.8) -> np.ndarray:
        """
        Stage 1: Remove background noise
        
        Args:
            audio: Input audio signal
            method: 'spectral' or 'wiener'
            noise_reduction: Strength of reduction (0-1)
        
        Returns:
            Denoised audio
        """
        if self.verbose:
            print("  [1/5] Denoising...")
        
        if method == 'spectral':
            reduced = nr.reduce_noise(
                y=audio,
                sr=self.sr,
                stationary=True,
                prop_decrease=noise_reduction
            )
        elif method == 'wiener':
            reduced = self._wiener_filter(audio)
        else:
            reduced = audio
        
        return reduced
    
    def _wiener_filter(self, audio: np.ndarray) -> np.ndarray:
        """Apply Wiener filtering for noise reduction"""
        noise_sample = audio[:int(0.5 * self.sr)]
        noise_power = np.var(noise_sample)
        signal_power = np.var(audio)
        wiener_gain = signal_power / (signal_power + noise_power + 1e-10)
        return audio * wiener_gain
    
    def enhance_bandwidth(self, audio: np.ndarray,
                         target_sr: int = 44100) -> np.ndarray:
        """
        Stage 2: Extend frequency bandwidth
        
        Args:
            audio: Input audio signal
            target_sr: Target sample rate for upsampling
        
        Returns:
            Bandwidth-enhanced audio
        """
        if self.verbose:
            print("  [2/5] Bandwidth enhancement...")
        
        # Upsample if needed
        if self.sr < target_sr:
            audio_high = librosa.resample(
                audio,
                orig_sr=self.sr,
                target_sr=target_sr
            )
            self.sr = target_sr
        else:
            audio_high = audio
        
        # Generate high-frequency harmonics
        audio_harmonics = self._generate_harmonics(audio_high)
        
        # Blend original with harmonics (70/30 mix)
        enhanced = 0.7 * audio_high + 0.3 * audio_harmonics
        
        return enhanced
    
    def _generate_harmonics(self, audio: np.ndarray) -> np.ndarray:
        """Synthesize high-frequency harmonic content"""
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/self.sr)
        
        # Boost frequencies above 8 kHz
        high_freq_mask = freqs > 8000
        fft[high_freq_mask] *= 1.5
        
        return np.fft.irfft(fft, len(audio))
    
    def compress_dynamics(self, audio: np.ndarray) -> np.ndarray:
        """
        Stage 3: Apply dynamic range compression
        
        Args:
            audio: Input audio signal
        
        Returns:
            Compressed audio
        """
        if self.verbose:
            print("  [3/5] Dynamic range compression...")
        
        compressed = self.compressor(audio, self.sr)
        return compressed
    
    def shape_spectrum(self, audio: np.ndarray) -> np.ndarray:
        """
        Stage 4: Apply spectral shaping and EQ
        
        Args:
            audio: Input audio signal
        
        Returns:
            Spectrally shaped audio
        """
        if self.verbose:
            print("  [4/5] Spectral shaping...")
        
        # Apply EQ filters
        shaped = self.eq_filters(audio, self.sr)
        
        # Enhance "air" frequencies (10-16 kHz)
        shaped = self._enhance_air(shaped)
        
        return shaped
    
    def _enhance_air(self, audio: np.ndarray, 
                     blend: float = 0.15) -> np.ndarray:
        """Boost high-frequency 'air' for presence"""
        sos = signal.butter(
            4, [10000, 16000], 
            'bandpass', 
            fs=self.sr, 
            output='sos'
        )
        air = signal.sosfilt(sos, audio)
        return (1 - blend) * audio + blend * air
    
    def normalize_and_finalize(self, audio: np.ndarray,
                               target_peak: float = 0.891) -> np.ndarray:
        """
        Stage 5: Peak normalization and dithering
        
        Args:
            audio: Input audio signal
            target_peak: Target peak level (0.891 = -1 dB)
        
        Returns:
            Normalized and dithered audio
        """
        if self.verbose:
            print("  [5/5] Normalization & finalization...")
        
        # Peak normalization
        peak = np.max(np.abs(audio))
        if peak > 0:
            normalized = audio * (target_peak / peak)
        else:
            normalized = audio
        
        # Add triangular dither to reduce quantization noise
        dither = np.random.triangular(-1, 0, 1, len(normalized)) * 0.0001
        dithered = normalized + dither
        
        # Safety clipping
        final = np.clip(dithered, -1.0, 1.0)
        
        return final
    
    def restore(self, 
                input_path: str,
                output_path: str,
                denoise_method: str = 'spectral',
                noise_reduction: float = 0.8) -> np.ndarray:
        """
        Execute full restoration pipeline
        
        Args:
            input_path: Path to input audio file
            output_path: Path to save restored audio
            denoise_method: Denoising method ('spectral' or 'wiener')
            noise_reduction: Noise reduction strength (0-1)
        
        Returns:
            Restored audio signal
        """
        if self.verbose:
            print(f"\nüîß Restoring: {input_path}")
        
        # Load audio
        audio, sr = librosa.load(input_path, sr=self.sr, mono=True)
        
        # Apply restoration pipeline
        audio = self.denoise(audio, method=denoise_method, 
                           noise_reduction=noise_reduction)
        audio = self.enhance_bandwidth(audio)
        audio = self.compress_dynamics(audio)
        audio = self.shape_spectrum(audio)
        audio = self.normalize_and_finalize(audio)
        
        # Save result
        sf.write(output_path, audio, self.sr, subtype='PCM_24')
        
        if self.verbose:
            print(f"‚úÖ Saved: {output_path}")
        
        return audio
    
    def batch_restore(self, 
                     input_files: list,
                     output_dir: str) -> list:
        """
        Restore multiple audio files
        
        Args:
            input_files: List of input file paths
            output_dir: Directory to save restored files
        
        Returns:
            List of output file paths
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        output_paths = []
        
        for input_path in input_files:
            basename = os.path.basename(input_path)
            output_path = os.path.join(output_dir, f"restored_{basename}")
            
            try:
                self.restore(input_path, output_path)
                output_paths.append(output_path)
            except Exception as e:
                print(f"‚ùå Error processing {basename}: {e}")
        
        return output_paths


def main():
    """Example usage"""
    restorer = AudioRestorer(sample_rate=32000, verbose=True)
    
    # Single file restoration
    restorer.restore(
        input_path="generated_audio/sample_1.wav",
        output_path="restored_audio/restored_sample_1.wav"
    )


if __name__ == "__main__":
    main()
